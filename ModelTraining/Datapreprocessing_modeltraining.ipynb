{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "1JuXMiFfP0DG"
   },
   "outputs": [],
   "source": [
    "#Import the necessary libraries \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "from collections import Counter\n",
    "from utilities import *\n",
    "from train_utils import *\n",
    "from sklearn.metrics import classification_report,confusion_matrix,roc_auc_score,average_precision_score,f1_score,recall_score, precision_score, balanced_accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load and transpose the train and test df to get features as columns\n",
    "train = pd.read_csv('homo_sapien-tox21_train.tsv', sep='\\t',header=None).T \n",
    "test = pd.read_csv('homo_sapien-tox21_test.tsv', sep='\\t',header=None).T "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7808, 5135)\n",
      "(628, 5135)\n"
     ]
    }
   ],
   "source": [
    "#Pre-process the trian and test data\n",
    "X_traindata=pre_proccess_df(df=train)\n",
    "print(X_traindata.shape)\n",
    "X_testdata=pre_proccess_df(df=test)\n",
    "print(X_testdata.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Br\n",
      "BrCC(Br)c1ccccc1\n"
     ]
    }
   ],
   "source": [
    "#Load the train and test labels datasets\n",
    "trainlabels = pd.read_csv('tox21_train_label.csv', header = 0)\n",
    "print(trainlabels.values[0,0])\n",
    "testlabels = pd.read_csv('tox21_test_label.csv', header = 0)\n",
    "print(testlabels.values[:,0][0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7808, 12)\n",
      "(628, 12)\n"
     ]
    }
   ],
   "source": [
    "#Pre-process the trian and test labels datasets\n",
    "train_labels=pre_proccess_labels(trainlabels,train=True)\n",
    "print(trainlabels.shape)\n",
    "test_labels=pre_proccess_labels(testlabels,train=False)\n",
    "print(testlabels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train data for the assay (6511, 5135)\n",
      "Shape of train labels for the assay (6511,)\n",
      "Shape of test data for the assay (592, 5135)\n",
      "Shape of test labels for the assay (592,)\n"
     ]
    }
   ],
   "source": [
    "#Get the dataset for each assay \n",
    "my_assay='nr-ahr'\n",
    "X_train, y_train, X_test, y_test=pre_proccess_dfassay(my_assay,X_traindata,train_labels,X_testdata, test_labels)\n",
    "print(\"Shape of train data for the assay\",X_train.shape)\n",
    "print(\"Shape of train labels for the assay\", y_train.shape)\n",
    "print(\"Shape of test data for the assay\",X_test.shape)\n",
    "print(\"Shape of test labels for the assay\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imbalanced ratio for the assay 7.87\n",
      "Imbalanced ratio for the assay 7.34\n"
     ]
    }
   ],
   "source": [
    "# Summarize class distribution using IR\n",
    "counter_train = Counter(y_train)\n",
    "counter_test = Counter(y_test)\n",
    "print(\"Imbalanced ratio for the assay {:0.2f}\".format(counter_train[0]/counter_train[1]))\n",
    "print(\"Imbalanced ratio for the assay {:0.2f}\".format( counter_test[0]/counter_test[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming SMOTEENN\n"
     ]
    }
   ],
   "source": [
    "#Generate the resampled data for the assay \n",
    "datasets= []\n",
    "datasets.append(transform(SMOTEENN(),X_train,y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______________________________________________________________\n",
      "SMOTEENN\n",
      "Fitting 30 folds for each of 10 candidates, totalling 300 fits\n",
      "Tuned Random Forest parameters: {'n_estimators': 500, 'max_depth': 47}\n",
      "Best estimator AUC score: 0.9992020418097709\n",
      "______________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Train the SMOTEENN+RF model on the resampled assay data\n",
    "benchmark_scores= []\n",
    "for sample_type,X,y in datasets:\n",
    "    print('______________________________________________________________')\n",
    "    print('{}'.format(sample_type))\n",
    "    benchmark_scores.append(benchmark(sample_type,X,y.values.ravel()))\n",
    "    print('______________________________________________________________')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training a SMOTEENN+RF\n"
     ]
    }
   ],
   "source": [
    "result = []\n",
    "# Train the model based on benchmark parameters\n",
    "for sampling_type,score,param in benchmark_scores:\n",
    "    print(\"Training a {}+RF\".format(sampling_type))\n",
    "    rf = RandomForestClassifier(**param)\n",
    "    for s_type,X,y in datasets:\n",
    "        if s_type == sampling_type:\n",
    "            rf.fit(X,y.values.ravel())\n",
    "            pred_test = rf.predict(X_test)\n",
    "            pred_test_probs = rf.predict_proba(X_test)[:,1]\n",
    "            cm = confusion_matrix(y_test, pred_test)\n",
    "            TN = cm[0][0]\n",
    "            FN = cm[1][0]\n",
    "            TP = cm[1][1]\n",
    "            FP = cm[0][1]\n",
    "                      \n",
    "            result.append((sampling_type, TN, FN, TP, FP,\n",
    "                           f1_score(y_test,pred_test),\n",
    "                           precision_score(y_test,pred_test),\n",
    "                           recall_score(y_test,pred_test),\n",
    "                           roc_auc_score(y_test, pred_test_probs),\n",
    "                           average_precision_score(y_test, pred_test_probs),\n",
    "                           balanced_accuracy_score(y_test, pred_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_result= pd.DataFrame(result,columns=['Sampling Type', \"TN\", \"FN\",\" TP\", \"FP\",'F1_score','Precision','Recall','AUCROC',\"AUPRC\",\"Balanced_Accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sampling Type</th>\n",
       "      <th>TN</th>\n",
       "      <th>FN</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>F1_score</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>AUCROC</th>\n",
       "      <th>AUPRC</th>\n",
       "      <th>Balanced_Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SMOTEENN</td>\n",
       "      <td>381</td>\n",
       "      <td>7</td>\n",
       "      <td>64</td>\n",
       "      <td>140</td>\n",
       "      <td>0.465455</td>\n",
       "      <td>0.313725</td>\n",
       "      <td>0.901408</td>\n",
       "      <td>0.898313</td>\n",
       "      <td>0.54667</td>\n",
       "      <td>0.816347</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Sampling Type   TN  FN   TP   FP  F1_score  Precision    Recall    AUCROC  \\\n",
       "0      SMOTEENN  381   7   64  140  0.465455   0.313725  0.901408  0.898313   \n",
       "\n",
       "     AUPRC  Balanced_Accuracy  \n",
       "0  0.54667           0.816347  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampling_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the feature importances by the fitted attribute feature_importances_ \n",
    "importances = rf.feature_importances_\n",
    "# Sort the feature importance in descending order (most important feature appears first)\n",
    "sorted_indices = np.argsort(importances)[::-1]\n",
    "#Get the top 100 most important features for the assay to run an enrichement analysis\n",
    "proteins=pd.DataFrame(X_train.columns[sorted_indices][:101], columns=['Important proteins(features)'])\n",
    "#Save the features to a csv file\n",
    "proteins.to_csv(\"{}__proteins.csv\".format(train.keys()[-1]))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Untitled1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "python (mycondaenv)",
   "language": "python",
   "name": "mycondaenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
